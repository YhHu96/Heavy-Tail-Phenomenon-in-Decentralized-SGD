{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54d5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6086319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cir(N):\n",
    "    x=np.zeros([N,N])\n",
    "    for i in range(1,N-1):\n",
    "        x[i][i]=1/3\n",
    "        x[i][i+1]=1/3\n",
    "        x[i][i-1]=1/3\n",
    "    x[N-1][N-2]=1/3\n",
    "    x[N-1][N-1]=1/3\n",
    "    x[N-1][0]=1/3\n",
    "    x[0][N-1]=1/3\n",
    "    x[0][0]=1/3\n",
    "    x[0][1]=1/3\n",
    "    return x\n",
    "\n",
    "def generate_ful(N):\n",
    "    x=np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            x[i][j]=1/N\n",
    "    return x\n",
    "\n",
    "def generate_star(N):\n",
    "    x = np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        if i ==0 :\n",
    "            for j in range(N):\n",
    "                x[i][j] = 1/N\n",
    "        else:\n",
    "            x[i][0] = 1/8\n",
    "            x[i][i] = 7/8\n",
    "    return x\n",
    "\n",
    "\n",
    "def alpha_estimator(m, X):\n",
    "    # X is N by d matrix\n",
    "    N = len(X)\n",
    "    n = int(N/m) # must be an integer\n",
    "    Y = np.sum(X.reshape((n, m, -1)), 1)\n",
    "    eps = np.spacing(1)\n",
    "    Y_log_norm = np.log(np.linalg.norm(Y, axis=1) + eps).mean()\n",
    "    X_log_norm = np.log(np.linalg.norm(X, axis=1) + eps).mean()\n",
    "    diff = (Y_log_norm - X_log_norm) / np.log(m)\n",
    "    return 1/diff\n",
    "\n",
    "# a_{i,j}: \\sim N (0, std_a^2 I_d)\n",
    "#  y = <a^T, x> + noise\n",
    "# noise \\sim N (0, std_noise^2)\n",
    "def generate_data(std_a, std_noise, d, batch):\n",
    "    data_a = []\n",
    "    data_y = []\n",
    "    for i in range(batch):\n",
    "        a = np.random.normal(0, std_a, d)\n",
    "        noise = np.random.normal(0, std_noise, 1)\n",
    "        y = np.dot(a, x_true) + noise\n",
    "        data_a.append(a)\n",
    "        data_y.append(y)\n",
    "    data_a = np.array(data_a)\n",
    "    data_y = np.array(data_y)\n",
    "    return data_a, data_y\n",
    "\n",
    "def MSE(x, data_a, data_y):\n",
    "    batch = len(data_y)\n",
    "    mse = 0\n",
    "    for i in range(batch):\n",
    "        diff = np.dot(data_a[i], x) - data_y[i]\n",
    "        mse += diff**2\n",
    "    return mse / (2*batch)\n",
    "\n",
    "def gradient(x, data_a, data_y):\n",
    "    batch = len(data_y)\n",
    "    grad = 0\n",
    "    for i in range(batch):\n",
    "        diff = np.dot(data_a[i], x) - data_y[i]\n",
    "        diff = diff / batch * data_a[i]\n",
    "        grad += diff\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5ee2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 8\n",
    "d = 100\n",
    "x_true = np.random.normal(0,3,d)\n",
    "X_true = np.ones((nodes,1)) @ x_true.reshape(1,-1)\n",
    "batch = 5\n",
    "iterations = 1000\n",
    "num_last_iters = 500\n",
    "std_nodes = [5] * nodes\n",
    "std_noise = 3\n",
    "num_exp = 1600\n",
    "# initialization \n",
    "x0 = np.random.uniform(-3,3,d)\n",
    "#batch_list = [1,2,3,4,5,6,7,8]\n",
    "lr = 0.18\n",
    "lr_list = np.linspace(0.165,0.205,num = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7cf55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xd = np.ones((1,1)) @ x0.reshape(1,-1)\n",
    "Xd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da99419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centralized start!\n",
      "0.1\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.10379310344827587\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.10758620689655173\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.11137931034482759\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.11517241379310345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.11896551724137931\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.12275862068965518\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.12655172413793103\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1303448275862069\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.13413793103448277\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.13793103448275862\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1417241379310345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.14551724137931035\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1493103448275862\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1531034482758621\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.15689655172413794\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1606896551724138\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16448275862068967\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1682758620689655\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17206896551724138\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17586206896551723\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17965517241379308\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18344827586206897\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18724137931034482\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19103448275862067\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19482758620689655\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1986206896551724\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.20241379310344826\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.20620689655172414\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.21\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "hypercube finished!\n"
     ]
    }
   ],
   "source": [
    "############################### Centralizaed\n",
    "w = [1]\n",
    "W = np.array(w)\n",
    "nodes = 1\n",
    "batch = 40\n",
    "print('centralized start!')\n",
    "\n",
    "\n",
    "lr_list = np.linspace(0.10,0.21,num = 30)\n",
    "final_iter_all = []\n",
    "error_iter_all = []\n",
    "for lr in lr_list:\n",
    "# for batch in batch_list:\n",
    "    print(lr)\n",
    "    Xd_across_exp = np.zeros((nodes, num_exp, d))\n",
    "    error_record_d_averaged = np.zeros(iterations)\n",
    "\n",
    "    for e in range(num_exp):\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(e)\n",
    "\n",
    "        Xd = np.ones((nodes,1)) @ x0.reshape(1,-1) # each row i is x[i]\n",
    "        error_record_d = np.zeros(iterations)\n",
    "        Xd_averaged = np.zeros((nodes, d))\n",
    "\n",
    "        for ite in range(iterations):\n",
    "\n",
    "            # sample data and get gradient\n",
    "            G = np.zeros((nodes, d)) # each row i is gradient of node i\n",
    "            for i in range(nodes):\n",
    "\n",
    "                # sample data\n",
    "                A = np.random.randn(batch, d)\n",
    "                noise = np.random.randn(batch,1) * std_noise\n",
    "                b = A @ x_true.reshape(-1,1) + noise\n",
    "\n",
    "                # compute gradient\n",
    "                g = (1/batch) * (A.T @ (A @ Xd[i,:].reshape(-1,1) - b))\n",
    "                G[i,:] = g.reshape(-1)\n",
    "\n",
    "            # main update\n",
    "            Xd = W @ Xd - lr * G\n",
    "            \n",
    "            # average the last 1000 iterates\n",
    "            if ite >= iterations - num_last_iters:\n",
    "                Xd_averaged += Xd\n",
    "\n",
    "            # compute distance to the true solution\n",
    "            error = np.linalg.norm(Xd - X_true,'fro')\n",
    "            error_record_d[ite] = error\n",
    "            \n",
    "        # fill in Xd_across_exp \n",
    "        Xd_averaged /= num_last_iters\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            Xd_across_exp[i,e] = Xd_averaged[i]\n",
    "            \n",
    "        error_record_d_averaged += error_record_d\n",
    "        \n",
    "    error_record_d_averaged = error_record_d_averaged/num_exp\n",
    "    final_iter_all.append(Xd_across_exp)\n",
    "    error_iter_all.append(error_record_d_averaged)\n",
    "np.save('./final_stepsize/final_iter_all_centnpy',final_iter_all)\n",
    "np.save('./final_stepsize/error_iter_cent.npy', error_iter_all)\n",
    "\n",
    "print('hypercube finished!')\n",
    "\n",
    "alpha_nodes_all = []\n",
    "#alpha_cent_all = []\n",
    "for l in range(len(final_iter_all)):\n",
    "    alpha_nodes = []\n",
    "    for i in range(nodes):\n",
    "        data_alpha = np.array(final_iter_all[l][i]-np.mean(final_iter_all[l][i],axis=0))\n",
    "        alpha_nodes.append(alpha_estimator(40, data_alpha))\n",
    "\n",
    "    #data_alpha = np.array(final_iter_cent_all[l]-np.mean(final_iter_cent_all[l], axis=0))\n",
    "    #alpha_cent = alpha_estimator(40, data_alpha)\n",
    "    alpha_nodes_all.append(alpha_nodes)\n",
    "    #alpha_cent_all.append(alpha_cent)\n",
    "alpha_nodes_all = np.transpose(alpha_nodes_all)\n",
    "\n",
    "np.save('./final_stepsize/alpha_nodes_cent_010-021.npy',alpha_nodes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf376142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0035321 , 2.00039592, 2.00224146, 2.02810599, 2.01470455,\n",
       "        2.02380676, 2.0325168 , 1.99406727, 2.01752581, 1.99030675,\n",
       "        2.00035605, 2.01220297, 2.02347685, 2.02638575, 2.02239196,\n",
       "        2.01629731, 2.0105959 , 2.0125512 , 1.98310412, 2.01271682,\n",
       "        2.02617723, 2.00838478, 2.00402965, 2.01318053, 2.00422068,\n",
       "        2.00941731, 2.00430651, 2.01974572, 2.01594642, 1.99813311]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_nodes_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d69f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### cycle\n",
    "W = generate_cir(nodes)\n",
    "print('cycle start!')\n",
    "\n",
    "final_iter_all = []\n",
    "error_iter_all = []\n",
    "for lr in lr_list:\n",
    "# for batch in batch_list:\n",
    "    print(lr)\n",
    "    Xd_across_exp = np.zeros((nodes, num_exp, d))\n",
    "    error_record_d_averaged = np.zeros(iterations)\n",
    "\n",
    "    for e in range(num_exp):\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(e)\n",
    "\n",
    "        Xd = np.ones((nodes,1)) @ x0.reshape(1,-1) # each row i is x[i]\n",
    "        error_record_d = np.zeros(iterations)\n",
    "        Xd_averaged = np.zeros((nodes, d))\n",
    "\n",
    "        for ite in range(iterations):\n",
    "\n",
    "            # sample data and get gradient\n",
    "            G = np.zeros((nodes, d)) # each row i is gradient of node i\n",
    "            for i in range(nodes):\n",
    "\n",
    "                # sample data\n",
    "                A = np.random.randn(batch, d)\n",
    "                noise = np.random.randn(batch,1) * std_noise\n",
    "                b = A @ x_true.reshape(-1,1) + noise\n",
    "\n",
    "                # compute gradient\n",
    "                g = (1/batch) * (A.T @ (A @ Xd[i,:].reshape(-1,1) - b))\n",
    "                G[i,:] = g.reshape(-1)\n",
    "\n",
    "            # main update\n",
    "            Xd = W @ Xd - lr * G\n",
    "            \n",
    "            # average the last 1000 iterates\n",
    "            if ite >= iterations - num_last_iters:\n",
    "                Xd_averaged += Xd\n",
    "\n",
    "            # compute distance to the true solution\n",
    "            error = np.linalg.norm(Xd - X_true,'fro')\n",
    "            error_record_d[ite] = error\n",
    "            \n",
    "        # fill in Xd_across_exp \n",
    "        Xd_averaged /= num_last_iters\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            Xd_across_exp[i,e] = Xd_averaged[i]\n",
    "            \n",
    "        error_record_d_averaged += error_record_d\n",
    "        \n",
    "    error_record_d_averaged = error_record_d_averaged/num_exp\n",
    "    final_iter_all.append(Xd_across_exp)\n",
    "    error_iter_all.append(error_record_d_averaged)\n",
    "np.save('./final_stepsize/final_iter_all_hyper.npy',final_iter_all)\n",
    "np.save('./final_stepsize/error_iter_hyper.npy', error_iter_all)\n",
    "\n",
    "print('hypercube finished!')\n",
    "\n",
    "alpha_nodes_all = []\n",
    "#alpha_cent_all = []\n",
    "for l in range(len(final_iter_all)):\n",
    "    alpha_nodes = []\n",
    "    for i in range(nodes):\n",
    "        data_alpha = np.array(final_iter_all[l][i]-np.mean(final_iter_all[l][i],axis=0))\n",
    "        alpha_nodes.append(alpha_estimator(40, data_alpha))\n",
    "\n",
    "    #data_alpha = np.array(final_iter_cent_all[l]-np.mean(final_iter_cent_all[l], axis=0))\n",
    "    #alpha_cent = alpha_estimator(40, data_alpha)\n",
    "    alpha_nodes_all.append(alpha_nodes)\n",
    "    #alpha_cent_all.append(alpha_cent)\n",
    "alpha_nodes_all = np.transpose(alpha_nodes_all)\n",
    "\n",
    "np.save('./final_stepsize/alpha_nodes_cir.npy',alpha_nodes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be736299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypercube start!\n",
      "0.165\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16637931034482759\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1677586206896552\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16913793103448277\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17051724137931035\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17189655172413792\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17327586206896553\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1746551724137931\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1760344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17741379310344826\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17879310344827587\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18017241379310345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18155172413793103\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1829310344827586\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1843103448275862\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1856896551724138\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18706896551724136\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18844827586206897\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18982758620689655\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19120689655172413\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1925862068965517\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1939655172413793\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1953448275862069\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19672413793103447\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19810344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19948275862068965\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.20086206896551723\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2022413793103448\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2036206896551724\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.205\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "hypercube finished!\n"
     ]
    }
   ],
   "source": [
    "############################### hypercube\n",
    "w = [[1,1,1,0,1,0,0,0],\n",
    "         [1,1,0,1,0,1,0,0],\n",
    "         [1,0,1,1,0,0,1,0],\n",
    "         [0,1,1,1,0,0,0,1],\n",
    "         [1,0,0,0,1,1,1,0],\n",
    "         [0,1,0,0,1,1,0,1],\n",
    "         [0,0,1,0,1,0,1,1],\n",
    "         [0,0,0,1,0,1,1,1]]\n",
    "w=np.array(w)\n",
    "W = w/4\n",
    "print('hypercube start!')\n",
    "\n",
    "final_iter_all = []\n",
    "error_iter_all = []\n",
    "for lr in lr_list:\n",
    "# for batch in batch_list:\n",
    "    print(lr)\n",
    "    Xd_across_exp = np.zeros((nodes, num_exp, d))\n",
    "    error_record_d_averaged = np.zeros(iterations)\n",
    "\n",
    "    for e in range(num_exp):\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(e)\n",
    "\n",
    "        Xd = np.ones((nodes,1)) @ x0.reshape(1,-1) # each row i is x[i]\n",
    "        error_record_d = np.zeros(iterations)\n",
    "        Xd_averaged = np.zeros((nodes, d))\n",
    "\n",
    "        for ite in range(iterations):\n",
    "\n",
    "            # sample data and get gradient\n",
    "            G = np.zeros((nodes, d)) # each row i is gradient of node i\n",
    "            for i in range(nodes):\n",
    "\n",
    "                # sample data\n",
    "                A = np.random.randn(batch, d)\n",
    "                noise = np.random.randn(batch,1) * std_noise\n",
    "                b = A @ x_true.reshape(-1,1) + noise\n",
    "\n",
    "                # compute gradient\n",
    "                g = (1/batch) * (A.T @ (A @ Xd[i,:].reshape(-1,1) - b))\n",
    "                G[i,:] = g.reshape(-1)\n",
    "\n",
    "            # main update\n",
    "            Xd = W @ Xd - lr * G\n",
    "            \n",
    "            # average the last 1000 iterates\n",
    "            if ite >= iterations - num_last_iters:\n",
    "                Xd_averaged += Xd\n",
    "\n",
    "            # compute distance to the true solution\n",
    "            error = np.linalg.norm(Xd - X_true,'fro')\n",
    "            error_record_d[ite] = error\n",
    "            \n",
    "        # fill in Xd_across_exp \n",
    "        Xd_averaged /= num_last_iters\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            Xd_across_exp[i,e] = Xd_averaged[i]\n",
    "            \n",
    "        error_record_d_averaged += error_record_d\n",
    "        \n",
    "    error_record_d_averaged = error_record_d_averaged/num_exp\n",
    "    final_iter_all.append(Xd_across_exp)\n",
    "    error_iter_all.append(error_record_d_averaged)\n",
    "np.save('./final_stepsize/final_iter_all_hyper.npy',final_iter_all)\n",
    "np.save('./final_stepsize/error_iter_hyper.npy', error_iter_all)\n",
    "\n",
    "print('hypercube finished!')\n",
    "\n",
    "alpha_nodes_all = []\n",
    "#alpha_cent_all = []\n",
    "for l in range(len(final_iter_all)):\n",
    "    alpha_nodes = []\n",
    "    for i in range(nodes):\n",
    "        data_alpha = np.array(final_iter_all[l][i]-np.mean(final_iter_all[l][i],axis=0))\n",
    "        alpha_nodes.append(alpha_estimator(40, data_alpha))\n",
    "\n",
    "    #data_alpha = np.array(final_iter_cent_all[l]-np.mean(final_iter_cent_all[l], axis=0))\n",
    "    #alpha_cent = alpha_estimator(40, data_alpha)\n",
    "    alpha_nodes_all.append(alpha_nodes)\n",
    "    #alpha_cent_all.append(alpha_cent)\n",
    "alpha_nodes_all = np.transpose(alpha_nodes_all)\n",
    "\n",
    "np.save('./final_stepsize/alpha_nodes_hyper.npy',alpha_nodes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "606763ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bipartite start!\n",
      "0.165\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16637931034482759\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1677586206896552\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16913793103448277\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17051724137931035\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17189655172413792\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17327586206896553\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1746551724137931\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1760344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17741379310344826\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17879310344827587\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18017241379310345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18155172413793103\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1829310344827586\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1843103448275862\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1856896551724138\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18706896551724136\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18844827586206897\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18982758620689655\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19120689655172413\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1925862068965517\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1939655172413793\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1953448275862069\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19672413793103447\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19810344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19948275862068965\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.20086206896551723\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2022413793103448\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2036206896551724\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.205\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "bipartite finished!\n"
     ]
    }
   ],
   "source": [
    "############################# bipartite\n",
    "\n",
    "W= [[1/5, 0, 0, 0, 1/5, 1/5, 1/5, 1/5 ],\n",
    "        [0, 1/5, 0, 0, 1/5, 1/5, 1/5, 1/5 ],\n",
    "        [0, 0, 1/5, 0, 1/5, 1/5, 1/5, 1/5 ],\n",
    "        [0, 0, 0, 1/5, 1/5, 1/5, 1/5, 1/5 ],\n",
    "        [1/5, 1/5, 1/5, 1/5, 1/5, 0, 0, 0 ],\n",
    "        [1/5, 1/5, 1/5, 1/5, 0, 1/5, 0, 0 ],\n",
    "        [1/5, 1/5, 1/5, 1/5, 0, 0, 1/5, 0 ],\n",
    "        [1/5, 1/5, 1/5, 1/5, 0, 0, 0, 1/5 ]]\n",
    "print('bipartite start!')\n",
    "\n",
    "final_iter_all = []\n",
    "error_iter_all = []\n",
    "for lr in lr_list:\n",
    "# for batch in batch_list:\n",
    "    print(lr)\n",
    "    Xd_across_exp = np.zeros((nodes, num_exp, d))\n",
    "    error_record_d_averaged = np.zeros(iterations)\n",
    "\n",
    "    for e in range(num_exp):\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(e)\n",
    "\n",
    "        Xd = np.ones((nodes,1)) @ x0.reshape(1,-1) # each row i is x[i]\n",
    "        error_record_d = np.zeros(iterations)\n",
    "        Xd_averaged = np.zeros((nodes, d))\n",
    "\n",
    "        for ite in range(iterations):\n",
    "\n",
    "            # sample data and get gradient\n",
    "            G = np.zeros((nodes, d)) # each row i is gradient of node i\n",
    "            for i in range(nodes):\n",
    "\n",
    "                # sample data\n",
    "                A = np.random.randn(batch, d)\n",
    "                noise = np.random.randn(batch,1) * std_noise\n",
    "                b = A @ x_true.reshape(-1,1) + noise\n",
    "\n",
    "                # compute gradient\n",
    "                g = (1/batch) * (A.T @ (A @ Xd[i,:].reshape(-1,1) - b))\n",
    "                G[i,:] = g.reshape(-1)\n",
    "\n",
    "            # main update\n",
    "            Xd = W @ Xd - lr * G\n",
    "            \n",
    "            # average the last 1000 iterates\n",
    "            if ite >= iterations - num_last_iters:\n",
    "                Xd_averaged += Xd\n",
    "\n",
    "            # compute distance to the true solution\n",
    "            error = np.linalg.norm(Xd - X_true,'fro')\n",
    "            error_record_d[ite] = error\n",
    "            \n",
    "        # fill in Xd_across_exp \n",
    "        Xd_averaged /= num_last_iters\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            Xd_across_exp[i,e] = Xd_averaged[i]\n",
    "            \n",
    "        error_record_d_averaged += error_record_d\n",
    "        \n",
    "    error_record_d_averaged = error_record_d_averaged/num_exp\n",
    "    final_iter_all.append(Xd_across_exp)\n",
    "    error_iter_all.append(error_record_d_averaged)\n",
    "np.save('./final_stepsize/final_iter_all_bipartite.npy',final_iter_all)\n",
    "np.save('./final_stepsize/error_iter_bipartite.npy', error_iter_all)\n",
    "\n",
    "print('bipartite finished!')\n",
    "\n",
    "alpha_nodes_all = []\n",
    "#alpha_cent_all = []\n",
    "for l in range(len(final_iter_all)):\n",
    "    alpha_nodes = []\n",
    "    for i in range(nodes):\n",
    "        data_alpha = np.array(final_iter_all[l][i]-np.mean(final_iter_all[l][i],axis=0))\n",
    "        alpha_nodes.append(alpha_estimator(40, data_alpha))\n",
    "\n",
    "    #data_alpha = np.array(final_iter_cent_all[l]-np.mean(final_iter_cent_all[l], axis=0))\n",
    "    #alpha_cent = alpha_estimator(40, data_alpha)\n",
    "    alpha_nodes_all.append(alpha_nodes)\n",
    "    #alpha_cent_all.append(alpha_cent)\n",
    "alpha_nodes_all = np.transpose(alpha_nodes_all)\n",
    "\n",
    "\n",
    "np.save('./final_stepsize/alpha_nodes_bipartite.npy',alpha_nodes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264e4ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00149168, 2.01060345, 2.00943218, 1.99912446, 2.02100271,\n",
       "        2.00008958, 2.01357283, 2.03529638, 2.0239131 , 2.00784758,\n",
       "        2.00265507, 1.99210849, 1.98966121, 1.92370586, 1.75728446,\n",
       "        1.36091902, 0.9978477 , 0.97211402, 0.90872681, 0.9342058 ,\n",
       "        0.96516107, 0.97220524, 0.86852138, 0.93748505, 0.92828194,\n",
       "        0.91387819, 0.90070373, 0.88757551, 0.91313061, 0.92281967],\n",
       "       [2.00006924, 2.02068465, 2.0008826 , 2.0236936 , 2.00623403,\n",
       "        2.00577063, 2.00502943, 2.0246032 , 2.03390353, 2.0174439 ,\n",
       "        2.01584017, 1.99534663, 1.99163613, 1.91519543, 1.74816036,\n",
       "        1.35534523, 0.99493129, 0.97387699, 0.90911436, 0.92069223,\n",
       "        0.9636631 , 0.97312486, 0.87714494, 0.94160646, 0.92512159,\n",
       "        0.91383828, 0.88964972, 0.88495259, 0.91846921, 0.9261128 ],\n",
       "       [1.99557489, 2.0287029 , 1.99423351, 2.00947466, 2.01370122,\n",
       "        1.98973064, 2.02648144, 2.03356643, 2.01839775, 2.02996272,\n",
       "        2.00006554, 1.98350364, 1.97410273, 1.92523662, 1.75911431,\n",
       "        1.36323481, 0.99325673, 0.97588208, 0.9043605 , 0.92890742,\n",
       "        0.95973139, 0.97070714, 0.87837284, 0.93526528, 0.92425997,\n",
       "        0.90930999, 0.88388017, 0.8871687 , 0.92563313, 0.93047148],\n",
       "       [2.00364463, 2.01208313, 2.00456771, 2.01326117, 2.01782079,\n",
       "        2.00304653, 2.01811358, 2.01051097, 2.00481097, 2.01855826,\n",
       "        1.9928838 , 2.00267847, 1.97791139, 1.91898038, 1.75177245,\n",
       "        1.34967485, 0.99387005, 0.97252622, 0.90115624, 0.93440161,\n",
       "        0.9627433 , 0.97300502, 0.87188465, 0.93839843, 0.93951125,\n",
       "        0.91150528, 0.87997446, 0.89806807, 0.91037158, 0.91646621],\n",
       "       [2.0230043 , 2.00967358, 2.00216072, 2.01970835, 2.01405379,\n",
       "        2.01405844, 2.01192315, 2.02827396, 2.02305961, 2.01930216,\n",
       "        2.00913097, 1.99407022, 1.97269817, 1.92112087, 1.75830223,\n",
       "        1.35852888, 0.99600428, 0.97401922, 0.91035432, 0.93441102,\n",
       "        0.95988217, 0.97163298, 0.86487969, 0.94532449, 0.92230355,\n",
       "        0.90758149, 0.86965997, 0.89384543, 0.91523747, 0.92617916],\n",
       "       [1.99401974, 2.02313454, 1.99908326, 2.01122722, 2.0154441 ,\n",
       "        2.0071757 , 2.01553154, 2.02657931, 2.02032927, 2.0286059 ,\n",
       "        2.00424053, 1.99596498, 1.99270455, 1.91757733, 1.75266402,\n",
       "        1.35924509, 0.99588335, 0.97195308, 0.90319538, 0.93238856,\n",
       "        0.96182083, 0.97274078, 0.87616979, 0.94329419, 0.92211564,\n",
       "        0.91322193, 0.88156891, 0.88793346, 0.91938598, 0.92222098],\n",
       "       [1.99986667, 2.02219061, 1.98903186, 2.01586131, 2.01369406,\n",
       "        2.00370081, 2.02081179, 2.03307561, 2.02575005, 2.00538963,\n",
       "        2.01842543, 1.99315525, 1.98065943, 1.92004744, 1.74432898,\n",
       "        1.35842818, 0.99906752, 0.97061684, 0.91265074, 0.93130358,\n",
       "        0.9656659 , 0.96836131, 0.88014456, 0.94317661, 0.92274815,\n",
       "        0.91166419, 0.88348969, 0.89808754, 0.91195632, 0.93075535],\n",
       "       [1.99710716, 2.01646709, 2.00746349, 2.0235209 , 2.00953468,\n",
       "        1.9953804 , 2.01978666, 2.03316617, 2.01366331, 2.02055306,\n",
       "        2.01160208, 1.99973488, 1.97995899, 1.9271662 , 1.75079881,\n",
       "        1.36005489, 0.99993711, 0.969417  , 0.90535106, 0.93026509,\n",
       "        0.96169675, 0.97185608, 0.87849599, 0.93599354, 0.90811571,\n",
       "        0.914661  , 0.88978863, 0.8927605 , 0.91586948, 0.9188943 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_nodes_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16882dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully start!\n",
      "0.165\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16637931034482759\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1677586206896552\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16913793103448277\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17051724137931035\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17189655172413792\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17327586206896553\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1746551724137931\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1760344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17741379310344826\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17879310344827587\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18017241379310345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18155172413793103\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1829310344827586\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1843103448275862\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1856896551724138\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18706896551724136\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18844827586206897\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18982758620689655\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19120689655172413\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1925862068965517\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1939655172413793\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1953448275862069\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19672413793103447\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19810344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19948275862068965\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.20086206896551723\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2022413793103448\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2036206896551724\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.205\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "fully finished!\n"
     ]
    }
   ],
   "source": [
    "W = generate_ful(nodes)\n",
    "print('fully start!')\n",
    "\n",
    "final_iter_all = []\n",
    "error_iter_all = []\n",
    "for lr in lr_list:\n",
    "    print(lr)\n",
    "    Xd_across_exp = np.zeros((nodes, num_exp, d))\n",
    "    error_record_d_averaged = np.zeros(iterations)\n",
    "\n",
    "    for e in range(num_exp):\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(e)\n",
    "\n",
    "        Xd = np.ones((nodes,1)) @ x0.reshape(1,-1) # each row i is x[i]\n",
    "        error_record_d = np.zeros(iterations)\n",
    "        Xd_averaged = np.zeros((nodes, d))\n",
    "\n",
    "        for ite in range(iterations):\n",
    "\n",
    "            # sample data and get gradient\n",
    "            G = np.zeros((nodes, d)) # each row i is gradient of node i\n",
    "            for i in range(nodes):\n",
    "\n",
    "                # sample data\n",
    "                A = np.random.randn(batch, d)\n",
    "                noise = np.random.randn(batch,1) * std_noise\n",
    "                b = A @ x_true.reshape(-1,1) + noise\n",
    "\n",
    "                # compute gradient\n",
    "                g = (1/batch) * (A.T @ (A @ Xd[i,:].reshape(-1,1) - b))\n",
    "                G[i,:] = g.reshape(-1)\n",
    "\n",
    "            # main update\n",
    "            Xd = W @ Xd - lr * G\n",
    "            \n",
    "            # average the last 1000 iterates\n",
    "            if ite >= iterations - num_last_iters:\n",
    "                Xd_averaged += Xd\n",
    "\n",
    "            # compute distance to the true solution\n",
    "            error = np.linalg.norm(Xd - X_true,'fro')\n",
    "            error_record_d[ite] = error\n",
    "            \n",
    "        # fill in Xd_across_exp \n",
    "        Xd_averaged /= num_last_iters\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            Xd_across_exp[i,e] = Xd_averaged[i]\n",
    "            \n",
    "        error_record_d_averaged += error_record_d\n",
    "        \n",
    "    error_record_d_averaged = error_record_d_averaged/num_exp\n",
    "    final_iter_all.append(Xd_across_exp)\n",
    "    error_iter_all.append(error_record_d_averaged)\n",
    "np.save('final_iter_all_fully.npy',final_iter_all)\n",
    "np.save('error_iter_fully.npy', error_iter_all)\n",
    "\n",
    "print('fully finished!')\n",
    "alpha_nodes_all = []\n",
    "for l in range(len(final_iter_all)):\n",
    "    alpha_nodes = []\n",
    "    for i in range(nodes):\n",
    "        data_alpha = np.array(final_iter_all[l][i]-np.mean(final_iter_all[l][i],axis=0))\n",
    "        alpha_nodes.append(alpha_estimator(40, data_alpha))\n",
    "\n",
    "    alpha_nodes_all.append(alpha_nodes)\n",
    "alpha_nodes_all = np.transpose(alpha_nodes_all)\n",
    "\n",
    "np.save('alpha_nodes_fully.npy',alpha_nodes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a3c0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star start!\n",
      "0.165\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16637931034482759\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1677586206896552\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.16913793103448277\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17051724137931035\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17189655172413792\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17327586206896553\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1746551724137931\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1760344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17741379310344826\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.17879310344827587\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18017241379310345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18155172413793103\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1829310344827586\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1843103448275862\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1856896551724138\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18706896551724136\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18844827586206897\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.18982758620689655\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19120689655172413\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1925862068965517\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1939655172413793\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.1953448275862069\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19672413793103447\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19810344827586207\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.19948275862068965\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.20086206896551723\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2022413793103448\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.2036206896551724\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.205\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "star finished!\n"
     ]
    }
   ],
   "source": [
    "def generate_star(N):\n",
    "    x = np.zeros([N,N])\n",
    "    for i in range(N):\n",
    "        if i ==0 :\n",
    "            for j in range(N):\n",
    "                x[i][j] = 1/N\n",
    "        else:\n",
    "            x[i][0] = 1/2\n",
    "            x[i][i] = 1/2\n",
    "    return x\n",
    "\n",
    "nodes = 8\n",
    "lr_list = np.linspace(0.165,0.205,num = 30)\n",
    "batch = 5\n",
    "############################### star\n",
    "W = generate_star(nodes)\n",
    "print('star start!')\n",
    "\n",
    "final_iter_all = []\n",
    "error_iter_all = []\n",
    "for lr in lr_list:\n",
    "# for batch in batch_list:\n",
    "    print(lr)\n",
    "    Xd_across_exp = np.zeros((nodes, num_exp, d))\n",
    "    error_record_d_averaged = np.zeros(iterations)\n",
    "\n",
    "    for e in range(num_exp):\n",
    "\n",
    "        if e%100 == 0:\n",
    "            print(e)\n",
    "\n",
    "        Xd = np.ones((nodes,1)) @ x0.reshape(1,-1) # each row i is x[i]\n",
    "        error_record_d = np.zeros(iterations)\n",
    "        Xd_averaged = np.zeros((nodes, d))\n",
    "\n",
    "        for ite in range(iterations):\n",
    "\n",
    "            # sample data and get gradient\n",
    "            G = np.zeros((nodes, d)) # each row i is gradient of node i\n",
    "            for i in range(nodes):\n",
    "\n",
    "                # sample data\n",
    "                A = np.random.randn(batch, d)\n",
    "                noise = np.random.randn(batch,1) * std_noise\n",
    "                b = A @ x_true.reshape(-1,1) + noise\n",
    "\n",
    "                # compute gradient\n",
    "                g = (1/batch) * (A.T @ (A @ Xd[i,:].reshape(-1,1) - b))\n",
    "                G[i,:] = g.reshape(-1)\n",
    "\n",
    "            # main update\n",
    "            Xd = W @ Xd - lr * G\n",
    "            \n",
    "            # average the last 1000 iterates\n",
    "            if ite >= iterations - num_last_iters:\n",
    "                Xd_averaged += Xd\n",
    "\n",
    "            # compute distance to the true solution\n",
    "            error = np.linalg.norm(Xd - X_true,'fro')\n",
    "            error_record_d[ite] = error\n",
    "            \n",
    "        # fill in Xd_across_exp \n",
    "        Xd_averaged /= num_last_iters\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            Xd_across_exp[i,e] = Xd_averaged[i]\n",
    "            \n",
    "        error_record_d_averaged += error_record_d\n",
    "        \n",
    "    error_record_d_averaged = error_record_d_averaged/num_exp\n",
    "    final_iter_all.append(Xd_across_exp)\n",
    "    error_iter_all.append(error_record_d_averaged)\n",
    "np.save('final_iter_all_star_new.npy',final_iter_all)\n",
    "np.save('error_iter_star_new.npy', error_iter_all)\n",
    "\n",
    "print('star finished!')\n",
    "\n",
    "alpha_nodes_all = []\n",
    "#alpha_cent_all = []\n",
    "for l in range(len(final_iter_all)):\n",
    "    alpha_nodes = []\n",
    "    for i in range(nodes):\n",
    "        data_alpha = np.array(final_iter_all[l][i]-np.mean(final_iter_all[l][i],axis=0))\n",
    "        alpha_nodes.append(alpha_estimator(40, data_alpha))\n",
    "\n",
    "    #data_alpha = np.array(final_iter_cent_all[l]-np.mean(final_iter_cent_all[l], axis=0))\n",
    "    #alpha_cent = alpha_estimator(40, data_alpha)\n",
    "    alpha_nodes_all.append(alpha_nodes)\n",
    "    #alpha_cent_all.append(alpha_cent)\n",
    "alpha_nodes_all = np.transpose(alpha_nodes_all)\n",
    "\n",
    "\n",
    "np.save('./final_stepsize/alpha_nodes_star_new.npy',alpha_nodes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6dc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
